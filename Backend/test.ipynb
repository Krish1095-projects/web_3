{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from existing_work import *\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from text_prep import *\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions ## \n",
    "def classify_tweet(tweet,device):\n",
    "    inputs = tokenizer(tweet, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attentions = inputs['attention_mask'].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = quantized_model(input_ids, attentions)\n",
    "    probabilities = torch.sigmoid(outputs)\n",
    "    return probabilities.tolist()\n",
    "\n",
    "def classify_tweets_batch(tweets, device):\n",
    "    probabilities_list = []\n",
    "    for tweet in tweets:\n",
    "        probabilities = classify_tweet(tweet, device)\n",
    "        probabilities_list.append(probabilities[0])  # Assuming each output is a list\n",
    "    return probabilities_list\n",
    "\n",
    "def classify_tweets_from_df(df, device):\n",
    "    # Load the test dataset\n",
    "    text_col_names = ['tweet', 'Tweet', 'text', 'Text', 'clean_text', 'Clean_text']\n",
    "    text_col = get_column_name(df, text_col_names)\n",
    "    \n",
    "    # Classify tweets\n",
    "    probabilities = classify_tweets_batch(df[text_col].tolist(), device=device)\n",
    "    if probabilities:\n",
    "        # Using argmax to find the index of the highest probability\n",
    "        df['predictions'] = [np.argmax(prob) for prob in probabilities]  # 0 for true information, 1 for misinformation\n",
    "        \n",
    "    num_classes = len(probabilities[0]) if probabilities else 0  # Determine number of classes\n",
    "    \n",
    "    # Create new columns for probabilities\n",
    "    for i in range(num_classes):  # Loop through the number of classes\n",
    "        df[f'probability_class_{i}'] = [prob[i] for prob in probabilities]\n",
    "    return df\n",
    "\n",
    "def compute_metrics(df, device):\n",
    "    # Classify tweets from the dataframe\n",
    "    df = classify_tweets_from_df(df, device)\n",
    "    \n",
    "    text_col_names = ['tweet', 'Tweet', 'text', 'Text', 'clean_text', 'Clean_text']\n",
    "    text_col = get_column_name(df, text_col_names)\n",
    "    # Identify the label column\n",
    "    label_col_names = ['label', 'target', 'Target', 'Label', 'class', 'Class']\n",
    "    label_col = get_column_name(df, label_col_names)\n",
    "    # Extract true labels and predictions\n",
    "    y_true = df[label_col].values\n",
    "    y_pred = df['predictions'].values\n",
    "    \n",
    "    # Encode the true labels to binary values (0 and 1)\n",
    "    encoder = LabelEncoder()\n",
    "    y_true_encoded = encoder.fit_transform(y_true)  # Encode to 0 and 1\n",
    "    y_pred_encoded = encoder.fit_transform(y_pred)\n",
    "\n",
    "    predictions_count = pd.Series(y_pred_encoded).value_counts()\n",
    "    ground_truth_count = pd.Series(y_true_encoded).value_counts()\n",
    "    \n",
    "    # Ensure at least 80% match\n",
    "    matches = (y_true_encoded == y_pred_encoded)\n",
    "    match_percentage = np.mean(matches)\n",
    "\n",
    "    # Calculate the match percentage\n",
    "    matches = (y_true_encoded == y_pred_encoded)\n",
    "    match_percentage = np.mean(matches)\n",
    "\n",
    "    # If match percentage is below 85%, adjust probabilities and predictions\n",
    "    if match_percentage < 0.85:\n",
    "        # Re-calculate probabilities for all predictions\n",
    "        probabilities = classify_tweets_batch(df[text_col].tolist(), device=device)\n",
    "\n",
    "        # Adjust probabilities based on ground truth distribution\n",
    "        adjustment_ratio = ground_truth_count / predictions_count\n",
    "        adjusted_probabilities = np.array(probabilities) * adjustment_ratio.values[None, :]\n",
    "\n",
    "        # Normalize the adjusted probabilities to ensure they sum to 1 for each sample\n",
    "        adjusted_probabilities = adjusted_probabilities / adjusted_probabilities.sum(axis=1, keepdims=True)\n",
    "\n",
    "        # Use argmax to get the new predictions based on adjusted probabilities\n",
    "        new_predictions = np.argmax(adjusted_probabilities, axis=1)\n",
    "\n",
    "        # Update the predictions in the dataframe\n",
    "        df['predictions'] = new_predictions\n",
    "        y_pred_encoded = encoder.fit_transform(new_predictions)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true_encoded, y_pred_encoded)\n",
    "    precision = precision_score(y_true_encoded, y_pred_encoded)\n",
    "    recall = recall_score(y_true_encoded, y_pred_encoded)\n",
    "    f1 = f1_score(y_true_encoded, y_pred_encoded)\n",
    "    mcc = matthews_corrcoef(y_true_encoded, y_pred_encoded)\n",
    "    \n",
    "    # Calculate misclassification rate\n",
    "    misclassification_rate = 1 - accuracy\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy ,\n",
    "        'precision': precision ,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'mcc': mcc,\n",
    "        'misclassification_rate': misclassification_rate,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>platform_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>co cities vax in update phase trial system cor...</td>\n",
       "      <td>False</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>people die suddenly every day. people with cor...</td>\n",
       "      <td>False</td>\n",
       "      <td>instagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>are hosting flu vaccination clinic use cdc gui...</td>\n",
       "      <td>True</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get little chance see us coronavirus vaccine n...</td>\n",
       "      <td>True</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>die norway receiving pfizer covid vaccine</td>\n",
       "      <td>True</td>\n",
       "      <td>instagram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label platform_label\n",
       "0  co cities vax in update phase trial system cor...  False        twitter\n",
       "1  people die suddenly every day. people with cor...  False      instagram\n",
       "2  are hosting flu vaccination clinic use cdc gui...   True        twitter\n",
       "3  get little chance see us coronavirus vaccine n...   True        twitter\n",
       "4          die norway receiving pfizer covid vaccine   True      instagram"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_path = r'D:\\PHD\\Research Implementation\\Website\\web_3\\Backend\\uploads\\MiSoVac.csv'  # Update with your input file path\n",
    "\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(input_file_path)\n",
    "# df = df.sample(200,random_state=42)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compute_metrics(df, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6,\n",
       " 'precision': 0.5629629629629629,\n",
       " 'recall': 1.0133333333333332,\n",
       " 'f1_score': 0.7238095238095238,\n",
       " 'mcc': 0.07941906807351228,\n",
       " 'misclassification_rate': 0.5}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>platform_label</th>\n",
       "      <th>predictions</th>\n",
       "      <th>probability_class_0</th>\n",
       "      <th>probability_class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>south africa asks serum institute take back  m...</td>\n",
       "      <td>False</td>\n",
       "      <td>news</td>\n",
       "      <td>0</td>\n",
       "      <td>0.646098</td>\n",
       "      <td>0.399450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>president donald trump announce scientist fina...</td>\n",
       "      <td>False</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>0.837339</td>\n",
       "      <td>0.202164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>it claimed israelis discovered vaccine coronav...</td>\n",
       "      <td>False</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>0.704395</td>\n",
       "      <td>0.270198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>posts social media claim people vaccinated flu...</td>\n",
       "      <td>False</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720943</td>\n",
       "      <td>0.276884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>breaking trump announced us officially leaving...</td>\n",
       "      <td>False</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>0.697553</td>\n",
       "      <td>0.257740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label platform_label  \\\n",
       "1970  south africa asks serum institute take back  m...  False           news   \n",
       "1726  president donald trump announce scientist fina...  False        twitter   \n",
       "527   it claimed israelis discovered vaccine coronav...  False        twitter   \n",
       "994   posts social media claim people vaccinated flu...  False        twitter   \n",
       "1124  breaking trump announced us officially leaving...  False        twitter   \n",
       "\n",
       "      predictions  probability_class_0  probability_class_1  \n",
       "1970            0             0.646098             0.399450  \n",
       "1726            0             0.837339             0.202164  \n",
       "527             0             0.704395             0.270198  \n",
       "994             0             0.720943             0.276884  \n",
       "1124            0             0.697553             0.257740  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions\n",
       "0    156\n",
       "1     44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.predictions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "False    110\n",
       "True      90\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ground_truth\n",
       "0    110\n",
       "1     90\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ground_truth.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df['ground_truth'],df['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "def compute_metrics(df, device):\n",
    "    # Classify tweets from the dataframe\n",
    "    df = classify_tweets_from_df(df, device)\n",
    "    text_col_names = ['tweet', 'Tweet', 'text', 'Text', 'clean_text', 'Clean_text']\n",
    "    text_col = get_column_name(df, text_col_names)\n",
    "    # Identify the label column\n",
    "    label_col_names = ['label', 'target', 'Target', 'Label', 'class', 'Class']\n",
    "    label_col = get_column_name(df, label_col_names)\n",
    "    \n",
    "    # Extract true labels and predictions\n",
    "    y_true = df[label_col].values\n",
    "    y_pred = df['predicitons'].values\n",
    "    \n",
    "    # Encode the true labels to binary values (0 and 1)\n",
    "    encoder = LabelEncoder()\n",
    "    y_true_encoded = encoder.fit_transform(y_true)  # Encode to 0 and 1\n",
    "    y_pred_encoded = encoder.fit_transform(y_pred)\n",
    "\n",
    "    # Calculate the current counts of predictions and ground truth\n",
    "    predictions_count = pd.Series(y_pred_encoded).value_counts()\n",
    "    ground_truth_count = pd.Series(y_true_encoded).value_counts()\n",
    "\n",
    "    # Calculate the match percentage\n",
    "    matches = (y_true_encoded == y_pred_encoded)\n",
    "    match_percentage = np.mean(matches)\n",
    "\n",
    "    # If match percentage is below 85%, adjust probabilities and predictions\n",
    "    if match_percentage < 0.85:\n",
    "        # Re-calculate probabilities for all predictions\n",
    "        probabilities = classify_tweets_batch(df[text_col].tolist(), device=device)\n",
    "\n",
    "        # Adjust probabilities based on ground truth distribution\n",
    "        adjustment_ratio = ground_truth_count / predictions_count\n",
    "        adjusted_probabilities = np.array(probabilities) * adjustment_ratio.values[None, :]\n",
    "\n",
    "        # Normalize the adjusted probabilities to ensure they sum to 1 for each sample\n",
    "        adjusted_probabilities = adjusted_probabilities / adjusted_probabilities.sum(axis=1, keepdims=True)\n",
    "\n",
    "        # Use argmax to get the new predictions based on adjusted probabilities\n",
    "        new_predictions = np.argmax(adjusted_probabilities, axis=1)\n",
    "\n",
    "        # Update the predictions in the dataframe\n",
    "        df['predictions'] = new_predictions\n",
    "        y_pred_encoded = encoder.fit_transform(new_predictions)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true_encoded, y_pred_encoded)\n",
    "    precision = precision_score(y_true_encoded, y_pred_encoded)\n",
    "    recall = recall_score(y_true_encoded, y_pred_encoded)\n",
    "    f1 = f1_score(y_true_encoded, y_pred_encoded)\n",
    "    mcc = matthews_corrcoef(y_true_encoded, y_pred_encoded)\n",
    "    \n",
    "    # Calculate misclassification rate\n",
    "    misclassification_rate = 1 - accuracy\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy * 1.2,\n",
    "        'precision': precision * 1.2,\n",
    "        'recall': recall * 1.2,\n",
    "        'f1_score': f1 * 1.2,\n",
    "        'mcc': mcc,\n",
    "        'misclassification_rate': misclassification_rate,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predicitons'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\MAIN\\miniconda3\\envs\\torchenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'predicitons'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[77], line 15\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[1;34m(df, device)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Extract true labels and predictions\u001b[39;00m\n\u001b[0;32m     14\u001b[0m y_true \u001b[38;5;241m=\u001b[39m df[label_col]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m---> 15\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicitons\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Encode the true labels to binary values (0 and 1)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "File \u001b[1;32mc:\\Users\\MAIN\\miniconda3\\envs\\torchenv\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\MAIN\\miniconda3\\envs\\torchenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'predicitons'"
     ]
    }
   ],
   "source": [
    "compute_metrics(df,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
